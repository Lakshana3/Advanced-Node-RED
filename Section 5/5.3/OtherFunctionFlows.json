[{"id":"456a6b59.67b1d4","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":60,"wires":[["f53abcab.e9055"]]},{"id":"f53abcab.e9055","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"payload","pt":"msg","to":"{\"faceId\":\"xxxxxxxxxxxxxxxxxxxxxxxxx\",\"largeFaceListId\":\"sample_list\",\"maxNumOfCandidatesReturned\":10,\"mode\":\"matchPerson\"}","tot":"json"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":60,"wires":[["53a84fc8.9dd7f"]]},{"id":"53a84fc8.9dd7f","type":"http request","z":"47814212.13592c","name":"Face POST Find Similar","method":"POST","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/findsimilars","tls":"","persist":false,"proxy":"","authType":"","x":750,"y":60,"wires":[["661c0581.b72f5c"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"661c0581.b72f5c","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":60,"wires":[]},{"id":"f73da4e.26cbd58","type":"comment","z":"47814212.13592c","name":"Face","info":"https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236","x":190,"y":60,"wires":[]},{"id":"6e2acd20.6d40b4","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":100,"wires":[["abf2a327.4949a"]]},{"id":"abf2a327.4949a","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"payload","pt":"msg","to":"{\"faceIds\":[\"c5c24a82-6845-4031-9d5d-978df9175426\",\"015839fb-fbd9-4f79-ace9-7675fc2f1dd9\",\"65d083d4-9447-47d1-af30-b626144bf0fb\",\"fce92aed-d578-4d2e-8114-068f8af4492e\",\"30ea1073-cc9e-4652-b1e3-d08fb7b95315\",\"be386ab3-af91-4104-9e6d-4dae4c9fddb7\",\"fbd2a038-dbff-452c-8e79-2ee81b1aa84e\",\"b64d5e15-8257-4af2-b20a-5a750f8940e7\"]}","tot":"json"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":100,"wires":[["837c4c8d.c5049"]]},{"id":"837c4c8d.c5049","type":"http request","z":"47814212.13592c","name":"Face POST Group","method":"POST","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/group","tls":"","persist":false,"proxy":"","authType":"","x":730,"y":100,"wires":[["ad305f0b.d0192"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"ad305f0b.d0192","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":100,"wires":[]},{"id":"8b51bb67.f7e9f8","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":140,"wires":[["bfb2ea9c.608328"]]},{"id":"bfb2ea9c.608328","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"payload","pt":"msg","to":"{\"faceId\":\"c5c24a82-6845-4031-9d5d-978df9175426\",\"personId\":\"815df99c-598f-4926-930a-a734b3fd651c\",\"largePersonGroupId\":\"sample_group\"}","tot":"json"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":140,"wires":[["9b79795f.98ec78"]]},{"id":"9b79795f.98ec78","type":"http request","z":"47814212.13592c","name":"Face POST Verify","method":"POST","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/verify","tls":"","persist":false,"proxy":"","authType":"","x":730,"y":140,"wires":[["88e76758.d0e648"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"88e76758.d0e648","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":140,"wires":[]},{"id":"eb39e9e9.4a8228","type":"comment","z":"47814212.13592c","name":"FaceList","info":"https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395250","x":180,"y":200,"wires":[]},{"id":"47577fe3.f8b5b","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":200,"wires":[["b10e3b1b.dd6dd8"]]},{"id":"b10e3b1b.dd6dd8","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"payload","pt":"msg","to":"{\"url\":\"http://example.com/1.jpg\"}","tot":"json"},{"t":"set","p":"faceListId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"userData","pt":"msg","to":"","tot":"str"},{"t":"set","p":"targetFace","pt":"msg","to":"","tot":"str"},{"t":"set","p":"detectionModel","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":200,"wires":[["f2207e09.00636"]]},{"id":"f2207e09.00636","type":"http request","z":"47814212.13592c","name":"FaceList POST Add Face","method":"POST","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/facelists/{{{faceListId}}}/persistedFaces?userData={{{userData}}}&targetFace={{{targetFace}}}&detectionModel={{{detectionModel}}}","tls":"","persist":false,"proxy":"","authType":"","x":750,"y":200,"wires":[["1a483ab3.b273d5"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"1a483ab3.b273d5","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":200,"wires":[]},{"id":"a7c782f6.59b1a","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":240,"wires":[["f91673f.f62759"]]},{"id":"f91673f.f62759","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"payload","pt":"msg","to":"{\"name\":\"sample_list\",\"userData\":\"User-provided data attached to the face list.\",\"recognitionModel\":\"recognition_02\"}","tot":"json"},{"t":"set","p":"faceListId","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":240,"wires":[["65bd459c.722bac"]]},{"id":"65bd459c.722bac","type":"http request","z":"47814212.13592c","name":"FaceList PUT Create","method":"DELETE","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/facelists/{{{faceListId}}}","tls":"","persist":false,"proxy":"","authType":"","x":740,"y":240,"wires":[["9c81fded.bf528"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"9c81fded.bf528","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":240,"wires":[]},{"id":"3093167f.95175a","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"faceListId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"persistedFaceId","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":320,"wires":[["7f6dcfeb.37f54"]]},{"id":"baa52d2a.3f0e4","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":320,"wires":[["3093167f.95175a"]]},{"id":"7f6dcfeb.37f54","type":"http request","z":"47814212.13592c","name":"FaceList DELETE Delete Face","method":"DELETE","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/facelists/{{{faceListId}}}/persistedFaces/{{{persistedFaceId}}}","tls":"","persist":false,"proxy":"","authType":"","x":770,"y":320,"wires":[["24449fc3.f3fb5"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"24449fc3.f3fb5","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":320,"wires":[]},{"id":"1cc20547.c8653b","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"faceListId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"returnRecognitionModel","pt":"msg","to":"true","tot":"bool"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":360,"wires":[["f9dd7ac9.e873f8"]]},{"id":"81ee1988.5eddd8","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":360,"wires":[["1cc20547.c8653b"]]},{"id":"f9dd7ac9.e873f8","type":"http request","z":"47814212.13592c","name":"FaceList GET Get","method":"GET","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/facelists/{{{faceListId}}}?returnRecognitionModel={{{returnRecognitionModel}}}","tls":"","persist":false,"proxy":"","authType":"","x":730,"y":360,"wires":[["f8236700.284d68"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"f8236700.284d68","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":360,"wires":[]},{"id":"5d379890.2c3de8","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"returnRecognitionModel","pt":"msg","to":"true","tot":"bool"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":400,"wires":[["83297e06.b3aea"]]},{"id":"dd05cab3.f9d038","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":400,"wires":[["5d379890.2c3de8"]]},{"id":"83297e06.b3aea","type":"http request","z":"47814212.13592c","name":"FaceList GET List","method":"GET","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/facelists?returnRecognitionModel={{{returnRecognitionModel}}}","tls":"","persist":false,"proxy":"","authType":"","x":730,"y":400,"wires":[["98aa938d.73658"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"98aa938d.73658","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":400,"wires":[]},{"id":"dfb3336c.c5da5","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"method","pt":"msg","to":"PATCH","tot":"str"},{"t":"set","p":"faceListId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"payload","pt":"msg","to":"{\"name\":\"list1\",\"userData\":\"User-provided data attached to the face list.\"}","tot":"json"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":440,"wires":[["5c690638.9e0b68"]]},{"id":"98272c8a.7c105","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":440,"wires":[["dfb3336c.c5da5"]]},{"id":"5c690638.9e0b68","type":"http request","z":"47814212.13592c","name":"FaceList PATCH Update","method":"use","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/facelists/{{{faceListId}}}","tls":"","persist":false,"proxy":"","authType":"","x":750,"y":440,"wires":[["a4116ac1.1a3328"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"a4116ac1.1a3328","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":440,"wires":[]},{"id":"5b91ccc6.c51014","type":"comment","z":"47814212.13592c","name":"LargeFaceList","info":"https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/5a158c10d2de3616c086f2d3","x":170,"y":500,"wires":[]},{"id":"eaca68ed.a98f18","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largeFaceListId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"userData","pt":"msg","to":"","tot":"str"},{"t":"set","p":"targetFace","pt":"msg","to":"","tot":"str"},{"t":"set","p":"detectionModel","pt":"msg","to":"","tot":"str"},{"t":"set","p":"payload","pt":"msg","to":"{\"url\":\"http://example.com/1.jpg\"}","tot":"json"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":500,"wires":[["f76c1802.83e338"]]},{"id":"1c9bac6b.a98de4","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":500,"wires":[["eaca68ed.a98f18"]]},{"id":"f76c1802.83e338","type":"http request","z":"47814212.13592c","name":"LargeFaceList POST Add Face","method":"POST","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largefacelists/{{{largeFaceListId}}}/persistedfaces?userData={{{userData}}}&targetFace={{{targetFace}}}&detectionModel={{{detectionModel}}}","tls":"","persist":false,"proxy":"","authType":"","x":770,"y":500,"wires":[["dffada68.3a3ca8"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"dffada68.3a3ca8","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":500,"wires":[]},{"id":"3cceaf22.32bc9","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largeFaceListId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"payload","pt":"msg","to":"{\"name\":\"large-face-list-name\",\"userData\":\"User-provided data attached to the large face list.\",\"recognitionModel\":\"recognition_02\"}","tot":"json"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":540,"wires":[["1d1c58ed.d93c97"]]},{"id":"57a9ee17.b5363","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":540,"wires":[["3cceaf22.32bc9"]]},{"id":"1d1c58ed.d93c97","type":"http request","z":"47814212.13592c","name":"LargeFaceList PUT Create","method":"PUT","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largefacelists/{{{largeFaceListId}}}","tls":"","persist":false,"proxy":"","authType":"","x":760,"y":540,"wires":[["ee90ed48.5c6ce"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"ee90ed48.5c6ce","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":540,"wires":[]},{"id":"eff5ad6b.22dd2","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"faceListId","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":280,"wires":[["9e364a2c.4ffea8"]]},{"id":"6434b8c6.4b2ed8","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":280,"wires":[["eff5ad6b.22dd2"]]},{"id":"9e364a2c.4ffea8","type":"http request","z":"47814212.13592c","name":"FaceList DELETE Delete ","method":"DELETE","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/facelists/{{{faceListId}}}","tls":"","persist":false,"proxy":"","authType":"","x":750,"y":280,"wires":[["77c41f1c.155d8"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"77c41f1c.155d8","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":280,"wires":[]},{"id":"e32da661.558558","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largeFaceListId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"persistedFaceId","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":620,"wires":[["5f2700be.1e132"]]},{"id":"e2b43b3f.1a1df8","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":620,"wires":[["e32da661.558558"]]},{"id":"5f2700be.1e132","type":"http request","z":"47814212.13592c","name":"LargeFaceList DELETE Delete Face","method":"DELETE","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largefacelists/{{{largeFaceListId}}}/persistedfaces/{{{persistedFaceId}}}","tls":"","persist":false,"proxy":"","authType":"","x":790,"y":620,"wires":[["a01be63b.70ead8"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"a01be63b.70ead8","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":620,"wires":[]},{"id":"384db78f.aa0fb8","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largeFaceListId","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":580,"wires":[["3afbffb8.27b85"]]},{"id":"d9076282.c9f6c","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":580,"wires":[["384db78f.aa0fb8"]]},{"id":"3afbffb8.27b85","type":"http request","z":"47814212.13592c","name":"LargeFaceList DELETE Delete ","method":"DELETE","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largefacelists/{{{largeFaceListId}}}","tls":"","persist":false,"proxy":"","authType":"","x":770,"y":580,"wires":[["462ac74c.662c48"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"462ac74c.662c48","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":580,"wires":[]},{"id":"5947f655.3369c8","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largeFaceListId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"returnRecognitionModel","pt":"msg","to":"true","tot":"bool"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":660,"wires":[["944e0d8c.19a25"]]},{"id":"8df2b26.74f585","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":660,"wires":[["5947f655.3369c8"]]},{"id":"944e0d8c.19a25","type":"http request","z":"47814212.13592c","name":"LargeFaceList GET Get","method":"GET","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largefacelists/{{{largeFaceListId}}}?returnRecognitionModel={{{returnRecognitionModel}}}","tls":"","persist":false,"proxy":"","authType":"","x":750,"y":660,"wires":[["7cc50bc1.2c00f4"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"7cc50bc1.2c00f4","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":660,"wires":[]},{"id":"376e6c18.fd7014","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largeFaceListId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"returnRecognitionModel","pt":"msg","to":"true","tot":"bool"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":700,"wires":[["8ed3a6d3.980458"]]},{"id":"d02ed55f.7f2b78","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":700,"wires":[["376e6c18.fd7014"]]},{"id":"8ed3a6d3.980458","type":"http request","z":"47814212.13592c","name":"LargeFaceList GET Get Face","method":"GET","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largefacelists/{{{largeFaceListId}}}/persistedfaces/{{{persistedFaceId}}}","tls":"","persist":false,"proxy":"","authType":"","x":760,"y":700,"wires":[["e1dd1d7e.5ea63"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"e1dd1d7e.5ea63","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":700,"wires":[]},{"id":"c164dfb1.967f9","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largeFaceListId","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":740,"wires":[["cbcfa001.9930d"]]},{"id":"a199a35.690476","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":740,"wires":[["c164dfb1.967f9"]]},{"id":"cbcfa001.9930d","type":"http request","z":"47814212.13592c","name":"LargeFaceList GET Get Training Status","method":"GET","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largefacelists/{{{largeFaceListId}}}/training","tls":"","persist":false,"proxy":"","authType":"","x":800,"y":740,"wires":[["b4eb9aea.c69468"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"b4eb9aea.c69468","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":740,"wires":[]},{"id":"cb62ff82.93283","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largeFaceListId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"start","pt":"msg","to":"","tot":"str"},{"t":"set","p":"top","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":820,"wires":[["fc96db78.508a78"]]},{"id":"8bd2942f.5011a8","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":820,"wires":[["cb62ff82.93283"]]},{"id":"fc96db78.508a78","type":"http request","z":"47814212.13592c","name":"LargeFaceList GET List Face","method":"GET","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largefacelists/{{{largeFaceListId}}}/persistedfaces?start={{{start}}}&top={{{top}}}","tls":"","persist":false,"proxy":"","authType":"","x":760,"y":820,"wires":[["90543fce.9041c"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"90543fce.9041c","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":820,"wires":[]},{"id":"5e487265.b6f8ac","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"start","pt":"msg","to":"","tot":"str"},{"t":"set","p":"top","pt":"msg","to":"","tot":"str"},{"t":"set","p":"returnRecognitionModel","pt":"msg","to":"true","tot":"bool"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":780,"wires":[["2061aca2.51a914"]]},{"id":"2e90e3c1.eb01fc","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":780,"wires":[["5e487265.b6f8ac"]]},{"id":"2061aca2.51a914","type":"http request","z":"47814212.13592c","name":"LargeFaceList GET List","method":"GET","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largefacelists?start={{{start}}}&top={{{top}}}&returnRecognitionModel={{{returnRecognitionModel}}}","tls":"","persist":false,"proxy":"","authType":"","x":750,"y":780,"wires":[["dee075a0.439ae8"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"dee075a0.439ae8","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":780,"wires":[]},{"id":"a5639568.ee9b28","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":860,"wires":[["41b4ab10.fee844"]]},{"id":"4af8535c.a4e21c","type":"http request","z":"47814212.13592c","name":"LargeFaceList POST Train","method":"POST","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largefacelists/{{{largeFaceListId}}}/train","tls":"","persist":false,"proxy":"","authType":"","x":760,"y":860,"wires":[["836cd2da.6b599"]],"info":"Submit a person group training task. Training is a crucial step that only a trained person group can be used by Face - Identify.\r\n\r\nThe training task is an asynchronous task. Training time depends on the number of person entries, and their faces in a person group. It could be several seconds to minutes. To check training status, please use PersonGroup - Get Training Status."},{"id":"836cd2da.6b599","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":860,"wires":[]},{"id":"41b4ab10.fee844","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largeFaceListId","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":860,"wires":[["4af8535c.a4e21c"]]},{"id":"4b62f440.04561c","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"method","pt":"msg","to":"PATCH","tot":"str"},{"t":"set","p":"largeFaceListId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"payload","pt":"msg","to":"{     \"name\": \"large-face-list-name\",     \"userData\": \"User-provided data attached to the large face list.\" }","tot":"json"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":900,"wires":[["82c7067a.bebd38"]]},{"id":"f4856fad.cc432","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":900,"wires":[["4b62f440.04561c"]]},{"id":"82c7067a.bebd38","type":"http request","z":"47814212.13592c","name":"LargeFaceList PATCH Update","method":"use","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largefacelists/{{{largeFaceListId}}}","tls":"","persist":false,"proxy":"","authType":"","x":770,"y":900,"wires":[["8fc1e1f3.77a46"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"8fc1e1f3.77a46","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":900,"wires":[]},{"id":"7950a062.bdb75","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"method","pt":"msg","to":"PATCH","tot":"str"},{"t":"set","p":"largeFaceListId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"persistedFaceId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"payload","pt":"msg","to":"{     \"userData\": \"User-provided data attached to the large face list face.\" }","tot":"json"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":940,"wires":[["13aca93.b475d57"]]},{"id":"3130969d.e9c2aa","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":940,"wires":[["7950a062.bdb75"]]},{"id":"13aca93.b475d57","type":"http request","z":"47814212.13592c","name":"LargeFaceList PATCH Update Face","method":"use","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largefacelists/{{{largeFaceListId}}}/persistedfaces/{{{persistedFaceId}}}","tls":"","persist":false,"proxy":"","authType":"","x":780,"y":940,"wires":[["3d233e1b.15d0e2"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"3d233e1b.15d0e2","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":940,"wires":[]},{"id":"917ebc38.c1b0a","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largePersonGroupId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"payload","pt":"msg","to":"{     \"name\": \"large-person-group-name\",     \"userData\": \"User-provided data attached to the large person group.\",     \"recognitionModel\": \"recognition_02\" }","tot":"json"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1000,"wires":[["8c09b80a.96d838"]]},{"id":"18663046.7ad32","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1000,"wires":[["917ebc38.c1b0a"]]},{"id":"8c09b80a.96d838","type":"http request","z":"47814212.13592c","name":"LargePersonGroup PUT Create","method":"PUT","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largepersongroups/{{{largePersonGroupId}}}","tls":"","persist":false,"proxy":"","authType":"","x":770,"y":1000,"wires":[["795f8fda.e73b7"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"795f8fda.e73b7","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1000,"wires":[]},{"id":"a25a18ae.765178","type":"comment","z":"47814212.13592c","name":"LargePersonGroup","info":"https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/599acdee6ac60f11b48b5a9d","x":150,"y":1000,"wires":[]},{"id":"800adf2e.30cbb","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largePersonGroupId","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1040,"wires":[["6e540373.f8776c"]]},{"id":"57edd204.5d1f6c","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1040,"wires":[["800adf2e.30cbb"]]},{"id":"6e540373.f8776c","type":"http request","z":"47814212.13592c","name":"LargePersonGroup DELETE Delete ","method":"DELETE","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largepersongroups/{{{largePersonGroupId}}}","tls":"","persist":false,"proxy":"","authType":"","x":780,"y":1040,"wires":[["afe4432d.0b38f"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"afe4432d.0b38f","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1040,"wires":[]},{"id":"63835ebf.eb353","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1080,"wires":[["a4ef4062.403aa"]]},{"id":"a4ef4062.403aa","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largePersonGroupId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"returnRecognitionModel","pt":"msg","to":"true","tot":"bool"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1080,"wires":[["a57cd9b.6d09e28"]]},{"id":"a57cd9b.6d09e28","type":"http request","z":"47814212.13592c","name":"LargePersonGroup GET Get","method":"GET","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largepersongroups/{{{largePersonGroupId}}}?returnRecognitionModel={{{returnRecognitionModel}}}","tls":"","persist":false,"proxy":"","authType":"","x":760,"y":1080,"wires":[["9c3bee65.6a2d9"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"9c3bee65.6a2d9","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1080,"wires":[]},{"id":"c3b3eaab.fb5098","type":"http request","z":"47814212.13592c","name":"LargePersonGroup GET Get Training Status","method":"GET","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largepersongroups/{{{largePersonGroupId}}}/training","tls":"","persist":false,"proxy":"","authType":"","x":810,"y":1120,"wires":[["62deae7b.4a2bd"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"62deae7b.4a2bd","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1120,"wires":[]},{"id":"1e2f997f.66ea67","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largePersonGroupId","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1120,"wires":[["c3b3eaab.fb5098"]]},{"id":"12c06cdd.500ad3","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1120,"wires":[["1e2f997f.66ea67"]]},{"id":"4f4d2287.f6557c","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1160,"wires":[["8280d3be.98e59"]]},{"id":"8280d3be.98e59","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"start","pt":"msg","to":"","tot":"str"},{"t":"set","p":"top","pt":"msg","to":"","tot":"str"},{"t":"set","p":"returnRecognitionModel","pt":"msg","to":"true","tot":"bool"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1160,"wires":[["dc4d1023.24c2a"]]},{"id":"dc4d1023.24c2a","type":"http request","z":"47814212.13592c","name":"LargePersonGroup GET List","method":"GET","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largepersongroups?start={{{start}}}&top={{{top}}}&returnRecognitionModel={{{returnRecognitionModel}}}","tls":"","persist":false,"proxy":"","authType":"","x":760,"y":1160,"wires":[["d35e891b.536d18"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"d35e891b.536d18","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1160,"wires":[]},{"id":"a2d74467.c1b608","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1200,"wires":[["6253739.47f3f8c"]]},{"id":"9492c6d4.07a418","type":"http request","z":"47814212.13592c","name":"LargePersonGroup POST Train","method":"POST","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largepersongroups/{{{largePersonGroupId}}}/train","tls":"","persist":false,"proxy":"","authType":"","x":770,"y":1200,"wires":[["e90b072.9bc2cf8"]],"info":"Submit a person group training task. Training is a crucial step that only a trained person group can be used by Face - Identify.\r\n\r\nThe training task is an asynchronous task. Training time depends on the number of person entries, and their faces in a person group. It could be several seconds to minutes. To check training status, please use PersonGroup - Get Training Status."},{"id":"e90b072.9bc2cf8","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1200,"wires":[]},{"id":"6253739.47f3f8c","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largePersonGroupId","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1200,"wires":[["9492c6d4.07a418"]]},{"id":"acb4405.f2c2dc","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"method","pt":"msg","to":"PATCH","tot":"str"},{"t":"set","p":"largePersonGroupId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"payload","pt":"msg","to":"{     \"name\": \"large-person-group-name\",     \"userData\": \"User-provided data attached to the large person group.\" }","tot":"json"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1240,"wires":[["83c6416.f68e8c"]]},{"id":"808440a.c45a3c","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1240,"wires":[["acb4405.f2c2dc"]]},{"id":"83c6416.f68e8c","type":"http request","z":"47814212.13592c","name":"LargePersonGroup PATCH Update","method":"use","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largepersongroups/{{{largePersonGroupId}}}","tls":"","persist":false,"proxy":"","authType":"","x":780,"y":1240,"wires":[["db1679b6.699ce8"]],"info":"Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.\r\n\r\n - No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted 24 hours after the original detection call.\r\n - Optional parameters include faceId, landmarks, and attributes. Attributes include age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure and noise. Some of the results returned for specific attributes may not be highly accurate.\r\n - JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n - The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n - Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.\r\n - For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).\r\n - Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n    *'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n    *'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.\r\n - Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to How to specify a recognition model.\r\n    *'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.\r\n    *'recognition_02': Recognition model released in 2019 March. 'recognition_02' is recommended since its overall accuracy is improved compared with 'recognition_01'."},{"id":"db1679b6.699ce8","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1240,"wires":[]},{"id":"defee056.c8e1d","type":"comment","z":"47814212.13592c","name":"LargePersonGroup Person","info":"https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/599adf2a3a7b9412a4d53f42","x":130,"y":1300,"wires":[]},{"id":"9af11aeb.6fe978","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1300,"wires":[["152cd39f.949acc"]]},{"id":"b01981e8.7c996","type":"http request","z":"47814212.13592c","name":"LargePersonGroup Person POST Add Face","method":"POST","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largepersongroups/{{{largePersonGroupId}}}/persons/{{{personId}}}/persistedFaces?userData={{{userData}}}&targetFace={{{targetFace}}}&detectionModel={{{detectionModel}}}","tls":"","persist":false,"proxy":"","authType":"","x":810,"y":1300,"wires":[["6a61dc81.a843d4"]],"info":"Add a face to a person into a person group for face identification or verification. To deal with an image containing multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature(s) will be stored on server until PersonGroup PersonFace - Delete, PersonGroup Person - Delete or PersonGroup - Delete is called.\r\nNote persistedFaceId is different from faceId generated by Face - Detect.\r\n\r\n * Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\r\n * Each person entry can hold up to 248 faces.\r\n * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n * \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from Face - Detect, there’s no guarantee to detect and add the face successfully.\r\n * Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\r\n * Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.\r\n * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n     - 'detection_01': The default detection model for PersonGroup Person - Add Face. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n     - 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces."},{"id":"6a61dc81.a843d4","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1300,"wires":[]},{"id":"152cd39f.949acc","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largePersonGroupId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"personId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"userData","pt":"msg","to":"","tot":"str"},{"t":"set","p":"targetFace","pt":"msg","to":"","tot":"str"},{"t":"set","p":"detectionModel","pt":"msg","to":"","tot":"str"},{"t":"set","p":"payload","pt":"msg","to":"{     \"url\": \"http://example.com/1.jpg\" }","tot":"json"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1300,"wires":[["b01981e8.7c996"]]},{"id":"1023b4df.cce50b","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1340,"wires":[["7d9ad9d2.4858f8"]]},{"id":"90cc418.fe36ec","type":"http request","z":"47814212.13592c","name":"LargePersonGroup Person POST Create","method":"POST","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largepersongroups/{{{largePersonGroupId}}}/persons","tls":"","persist":false,"proxy":"","authType":"","x":800,"y":1340,"wires":[["ad7cbb81.253478"]],"info":"Create a new person in a specified person group. To add face to this person, please call PersonGroup PersonFace - Add.\r\n\r\n * Free-tier subscription quota:\r\n     - 1,000 persons in all person groups.\r\n * S0-tier subscription quota:\r\n     - 10,000 persons per person group.\r\n     - 1,000,000 person groups.\r\n     - 100,000,000 persons in all person groups."},{"id":"ad7cbb81.253478","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1340,"wires":[]},{"id":"7d9ad9d2.4858f8","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largePersonGroupId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"payload","pt":"msg","to":"{     \"name\": \"person-name\",     \"userData\": \"User-provided data attached to the person.\" }","tot":"json"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1340,"wires":[["90cc418.fe36ec"]]},{"id":"44e63f28.bb83e","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1380,"wires":[["6a7c358d.5e58cc"]]},{"id":"4fae24ee.560f4c","type":"http request","z":"47814212.13592c","name":"LargePersonGroup Person DELETE Delete","method":"DELETE","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largepersongroups/{{{largePersonGroupId}}}/persons/{{{personId}}}","tls":"","persist":false,"proxy":"","authType":"","x":810,"y":1380,"wires":[["e3b62dd2.18b11"]],"info":"Delete an existing person from a person group. The persistedFaceId, userData, person name and face feature(s) in the person entry will all be deleted."},{"id":"e3b62dd2.18b11","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1380,"wires":[]},{"id":"6a7c358d.5e58cc","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largePersonGroupId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"personId","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1380,"wires":[["4fae24ee.560f4c"]]},{"id":"430eeb96.465f74","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1420,"wires":[["f883255f.fd0df8"]]},{"id":"d1d2649.d2bcc98","type":"http request","z":"47814212.13592c","name":"LargePersonGroup Person DELETE Delete Face","method":"DELETE","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largepersongroups/{{{largePersonGroupId}}}/persons/{{{personId}}}/persistedFaces/{{{persistedFaceId}}}","tls":"","persist":false,"proxy":"","authType":"","x":830,"y":1420,"wires":[["5a64e029.93b11"]],"info":"Delete a face from a person in a person group by specified personGroupId, personId and persistedFaceId.\r\nAdding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel."},{"id":"5a64e029.93b11","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1420,"wires":[]},{"id":"f883255f.fd0df8","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largePersonGroupId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"personId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"persistedFaceId","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1420,"wires":[["d1d2649.d2bcc98"]]},{"id":"811afc48.79b5f","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1460,"wires":[["87a2fcdc.712a1"]]},{"id":"a48b67ba.807928","type":"http request","z":"47814212.13592c","name":"LargePersonGroup Person GET Get","method":"GET","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largepersongroups/{{{largePersonGroupId}}}/persons/{{{personId}}}","tls":"","persist":false,"proxy":"","authType":"","x":790,"y":1460,"wires":[["4ed588d7.392e08"]],"info":"Retrieve a person's name and userData, and the persisted faceIds representing the registered person face feature(s)."},{"id":"4ed588d7.392e08","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1460,"wires":[]},{"id":"87a2fcdc.712a1","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largePersonGroupId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"personId","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1460,"wires":[["a48b67ba.807928"]]},{"id":"dc9cd8a.6ff0628","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1500,"wires":[["5a8b3aae.af7b24"]]},{"id":"239cef54.cb997","type":"http request","z":"47814212.13592c","name":"LargePersonGroup Person GET Get Face","method":"GET","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largepersongroups/{{{largePersonGroupId}}}/persons/{{{personId}}}/persistedFaces/{{{persistedFaceId}}}","tls":"","persist":false,"proxy":"","authType":"","x":800,"y":1500,"wires":[["2e12d001.61b92"]],"info":"Retrieve person face information. The persisted person face is specified by its personGroupId, personId and persistedFaceId."},{"id":"2e12d001.61b92","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1500,"wires":[]},{"id":"5a8b3aae.af7b24","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largePersonGroupId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"personId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"persistedFaceId","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1500,"wires":[["239cef54.cb997"]]},{"id":"5938ec5b.e94064","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largePersonGroupId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"start","pt":"msg","to":"","tot":"str"},{"t":"set","p":"top","pt":"msg","to":"","tot":"num"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1540,"wires":[["876fd62f.bda388"]]},{"id":"c9f5fb94.c26358","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1540,"wires":[["5938ec5b.e94064"]]},{"id":"876fd62f.bda388","type":"http request","z":"47814212.13592c","name":"LargePersonGroup Person GET List","method":"GET","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largepersongroups/{{{largePersonGroupId}}}/persons?start={{{start}}}&top={{{top}}}","tls":"","persist":false,"proxy":"","authType":"","x":790,"y":1540,"wires":[["280320ce.0a511"]],"info":"List all persons’ information in the specified person group, including personId, name, userData and persistedFaceIds of registered person faces.\r\n\r\n - Persons are stored in alphabetical order of personId created in PersonGroup Person - Create.\r\n - \"start\" parameter (string, optional) is a personId value that returned entries have larger ids by string comparison. \"start\" set to empty to indicate return from the first item.\r\n - \"top\" parameter (int, optional) specifies the number of entries to return. A maximal of 1000 entries can be returned in one call. To fetch more, you can specify \"start\" with the last returned entry’s personId of the current call.\r\nFor example, total 5 persons with their personId: \"personId1\", ..., \"personId5\".\r\n\"start=&top=\" will return all 5 persons.\r\n\"start=&top=2\" will return \"personId1\", \"personId2\".\r\n\"start=personId2&top=3\" will return \"personId3\", \"personId4\", \"personId5\"."},{"id":"280320ce.0a511","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1540,"wires":[]},{"id":"1f763161.15aa3f","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1580,"wires":[["b8109c01.29b2"]]},{"id":"30bc7210.6233be","type":"http request","z":"47814212.13592c","name":"LargePersonGroup Person PATCH Update","method":"use","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largepersongroups/{{{largePersonGroupId}}}/persons/{{{personId}}}","tls":"","persist":false,"proxy":"","authType":"","x":810,"y":1580,"wires":[["88dc534e.a3334"]],"info":"Update name or userData of a person."},{"id":"88dc534e.a3334","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1580,"wires":[]},{"id":"b8109c01.29b2","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"method","pt":"msg","to":"PATCH","tot":"str"},{"t":"set","p":"largePersonGroupId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"personId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"payload","pt":"msg","to":"{     \"name\": \"person-name\",     \"userData\": \"User-provided data attached to the person.\" }","tot":"json"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1580,"wires":[["30bc7210.6233be"]]},{"id":"ea32e3b6.12368","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1620,"wires":[["b26974e0.cb4898"]]},{"id":"16f78a7.98ecf76","type":"http request","z":"47814212.13592c","name":"LargePersonGroup Person PATCH Update Face","method":"use","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/largepersongroups/{{{largePersonGroupId}}}/persons/{{{personId}}}/persistedFaces/{{{persistedFaceId}}}","tls":"","persist":false,"proxy":"","authType":"","x":820,"y":1620,"wires":[["c338b451.077d18"]],"info":"Update a person persisted face's userData field."},{"id":"c338b451.077d18","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1620,"wires":[]},{"id":"b26974e0.cb4898","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"method","pt":"msg","to":"PATCH","tot":"str"},{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"largePersonGroupId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"personId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"persistedFaceId","pt":"msg","to":"","tot":"str"},{"t":"set","p":"payload","pt":"msg","to":"{     \"userData\": \"User-provided data attached to the person face.\" }","tot":"json"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1620,"wires":[["16f78a7.98ecf76"]]},{"id":"49232acd.1047c4","type":"comment","z":"47814212.13592c","name":"Snapshot","info":"https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/snapshot-apply","x":180,"y":1680,"wires":[]},{"id":"204da92c.0b9176","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1680,"wires":[["44e7312.d49edd"]]},{"id":"24c60e9c.2cad72","type":"http request","z":"47814212.13592c","name":"Snapshot POST Apply ","method":"POST","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/snapshots/{{{snapshot_id}}}/apply","tls":"","persist":false,"proxy":"","authType":"","x":740,"y":1680,"wires":[["a8644d5a.376cf"]],"info":"Add a face to a person into a person group for face identification or verification. To deal with an image containing multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature(s) will be stored on server until PersonGroup PersonFace - Delete, PersonGroup Person - Delete or PersonGroup - Delete is called.\r\nNote persistedFaceId is different from faceId generated by Face - Detect.\r\n\r\n * Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\r\n * Each person entry can hold up to 248 faces.\r\n * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n * \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from Face - Detect, there’s no guarantee to detect and add the face successfully.\r\n * Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\r\n * Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.\r\n * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n     - 'detection_01': The default detection model for PersonGroup Person - Add Face. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n     - 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces."},{"id":"a8644d5a.376cf","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1680,"wires":[]},{"id":"44e7312.d49edd","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"snapshot_id","pt":"msg","to":"","tot":"str"},{"t":"set","p":"payload","pt":"msg","to":"{ \t\"objectId\": \"person_group_id1\", \t\"mode\": \"CreateNew\" }","tot":"json"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1680,"wires":[["24c60e9c.2cad72"]]},{"id":"babfaa6d.59a418","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1720,"wires":[["4170cc9d.8e5084"]]},{"id":"360212d9.fb99ae","type":"http request","z":"47814212.13592c","name":"Snapshot DELETE Delete","method":"DELETE","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/snapshots/{{{snapshot_id}}}","tls":"","persist":false,"proxy":"","authType":"","x":750,"y":1720,"wires":[["3915396c.1879d6"]],"info":"Add a face to a person into a person group for face identification or verification. To deal with an image containing multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature(s) will be stored on server until PersonGroup PersonFace - Delete, PersonGroup Person - Delete or PersonGroup - Delete is called.\r\nNote persistedFaceId is different from faceId generated by Face - Detect.\r\n\r\n * Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\r\n * Each person entry can hold up to 248 faces.\r\n * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n * \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from Face - Detect, there’s no guarantee to detect and add the face successfully.\r\n * Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\r\n * Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.\r\n * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n     - 'detection_01': The default detection model for PersonGroup Person - Add Face. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n     - 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces."},{"id":"3915396c.1879d6","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1720,"wires":[]},{"id":"4170cc9d.8e5084","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"snapshot_id","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1720,"wires":[["360212d9.fb99ae"]]},{"id":"30db647d.8cd21c","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1760,"wires":[["fce971e4.56cd5"]]},{"id":"6add6382.ed728c","type":"http request","z":"47814212.13592c","name":"Snapshot GET Get Operation Status","method":"GET","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/operations/{{{operation_id}}}","tls":"","persist":false,"proxy":"","authType":"","x":790,"y":1760,"wires":[["641dce7c.d3ab6"]],"info":"Add a face to a person into a person group for face identification or verification. To deal with an image containing multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature(s) will be stored on server until PersonGroup PersonFace - Delete, PersonGroup Person - Delete or PersonGroup - Delete is called.\r\nNote persistedFaceId is different from faceId generated by Face - Detect.\r\n\r\n * Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\r\n * Each person entry can hold up to 248 faces.\r\n * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n * \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from Face - Detect, there’s no guarantee to detect and add the face successfully.\r\n * Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\r\n * Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.\r\n * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n     - 'detection_01': The default detection model for PersonGroup Person - Add Face. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n     - 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces."},{"id":"641dce7c.d3ab6","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1760,"wires":[]},{"id":"fce971e4.56cd5","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"operation_id","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1760,"wires":[["6add6382.ed728c"]]},{"id":"3c1a54b2.ded57c","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1800,"wires":[["923a6d2c.b210b"]]},{"id":"595d46d2.9baee8","type":"http request","z":"47814212.13592c","name":"Snapshot GET List","method":"GET","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/snapshots?type={{{type}}}&applyScope={{{applyScope}}}","tls":"","persist":false,"proxy":"","authType":"","x":730,"y":1800,"wires":[["5d450c70.a71434"]],"info":"Add a face to a person into a person group for face identification or verification. To deal with an image containing multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature(s) will be stored on server until PersonGroup PersonFace - Delete, PersonGroup Person - Delete or PersonGroup - Delete is called.\r\nNote persistedFaceId is different from faceId generated by Face - Detect.\r\n\r\n * Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\r\n * Each person entry can hold up to 248 faces.\r\n * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n * \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from Face - Detect, there’s no guarantee to detect and add the face successfully.\r\n * Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\r\n * Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.\r\n * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n     - 'detection_01': The default detection model for PersonGroup Person - Add Face. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n     - 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces."},{"id":"5d450c70.a71434","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1800,"wires":[]},{"id":"923a6d2c.b210b","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"type","pt":"msg","to":"","tot":"str"},{"t":"set","p":"applyScope","pt":"msg","to":"","tot":"str"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1800,"wires":[["595d46d2.9baee8"]]},{"id":"210c9cf2.f368d4","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1840,"wires":[["bea90ddb.a5e6b"]]},{"id":"9a9b0d65.d332f","type":"http request","z":"47814212.13592c","name":"Snapshot POST Take","method":"POST","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/snapshots","tls":"","persist":false,"proxy":"","authType":"","x":740,"y":1840,"wires":[["c9806ee4.65c4c"]],"info":"Add a face to a person into a person group for face identification or verification. To deal with an image containing multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature(s) will be stored on server until PersonGroup PersonFace - Delete, PersonGroup Person - Delete or PersonGroup - Delete is called.\r\nNote persistedFaceId is different from faceId generated by Face - Detect.\r\n\r\n * Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\r\n * Each person entry can hold up to 248 faces.\r\n * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n * \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from Face - Detect, there’s no guarantee to detect and add the face successfully.\r\n * Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\r\n * Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.\r\n * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n     - 'detection_01': The default detection model for PersonGroup Person - Add Face. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n     - 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces."},{"id":"c9806ee4.65c4c","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1840,"wires":[]},{"id":"bea90ddb.a5e6b","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"payload","pt":"msg","to":"{     \"type\": \"PersonGroup\",     \"objectId\": \"test_snapshot\",     \"applyScope\": [\"f9b96b36-1f5e-4021-8959-51527e26e6d3\"],     \"userData\": \"{user provided user data}\" }","tot":"json"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1840,"wires":[["9a9b0d65.d332f"]]},{"id":"c31fc6f2.467178","type":"inject","z":"47814212.13592c","name":"","topic":"","payload":"","payloadType":"date","repeat":"","crontab":"","once":false,"onceDelay":0.1,"x":340,"y":1880,"wires":[["b2938497.a667e8"]]},{"id":"f17d45c2.bb6d28","type":"http request","z":"47814212.13592c","name":"Snapshot PATCH Update","method":"use","ret":"obj","paytoqs":false,"url":"https://westus.api.cognitive.microsoft.com/face/v1.0/snapshots/{{{snapshot_id}}}","tls":"","persist":false,"proxy":"","authType":"","x":750,"y":1880,"wires":[["842c075.3871cf8"]],"info":"Add a face to a person into a person group for face identification or verification. To deal with an image containing multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. No image will be stored. Only the extracted face feature(s) will be stored on server until PersonGroup PersonFace - Delete, PersonGroup Person - Delete or PersonGroup - Delete is called.\r\nNote persistedFaceId is different from faceId generated by Face - Detect.\r\n\r\n * Higher face image quality means better recognition precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.\r\n * Each person entry can hold up to 248 faces.\r\n * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\r\n * \"targetFace\" rectangle should contain one face. Zero or multiple faces will be regarded as an error. If the provided \"targetFace\" rectangle is not returned from Face - Detect, there’s no guarantee to detect and add the face successfully.\r\n * Out of detectable face size (36x36 - 4096x4096 pixels), large head-pose, or large occlusions will cause failures.\r\n * Adding/deleting faces to/from a same person will be processed sequentially. Adding/deleting faces to/from different persons are processed in parallel.\r\n * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.\r\n * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to How to specify a detection model\r\n     - 'detection_01': The default detection model for PersonGroup Person - Add Face. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.\r\n     - 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces."},{"id":"842c075.3871cf8","type":"debug","z":"47814212.13592c","name":"","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","x":1110,"y":1880,"wires":[]},{"id":"b2938497.a667e8","type":"change","z":"47814212.13592c","name":"","rules":[{"t":"set","p":"headers","pt":"msg","to":"{\"Content-Type\":\"application/json\",\"Ocp-Apim-Subscription-Key\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxx\"}","tot":"json"},{"t":"set","p":"snapshot_id","pt":"msg","to":"","tot":"str"},{"t":"set","p":"payload","pt":"msg","to":"{ \t\"applyScope\": [\"25985303-c537-4467-b41d-bdb45cd95ca1\"], \t\"userData\": \"{user provided user data}\" }","tot":"json"}],"action":"","property":"","from":"","to":"","reg":false,"x":520,"y":1880,"wires":[["f17d45c2.bb6d28"]]}]